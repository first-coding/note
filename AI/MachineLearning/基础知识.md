- 机器学习：类似人通过对经验的利用，对新情况做出有效的决策。在机器学习领域，**经验->数据，学习算法基于数据得出模型（从数据中学到的结果）**
	- 每一条数据就是一条记录，记录的集合就是**数据集**。
	- 一条记录是关于一个事件或对象的描述。
		- eg: 西瓜的根蒂、敲声、色泽就是**属性**。属性上的值就是**属性值**，每一条记录就是对一个西瓜的描述。
		- 属性的值形成的空间就是**属性空间，样本空间**
		- 在**属性空间中**的每一条记录都可以找到对应的点。每个点就是**特征向量**。
	- 从数据中学到模型的过程称为**学习/训练**。
		- 用于学习/训练的数据集就是**训练集**
		- 训练集中的每一条数据就是**训练样本**
		- 特征值得到的是**标签**，有标签的记录是一个**样例（xi,yi）** yi表示xi的标记，y是所有标记集合。称为**标记空间**
	- 连续值和离散值：
		- 连续值：eg:0.95，0.37
		- 离散值：eg:西瓜分类是好瓜还是坏瓜，好瓜或者坏瓜就是离散值
	- 是否有标记信息：监督学习和无监督学习。
	- **泛化能力**：模型适用于新样本的能力。
	- 归纳和演绎：
		- 归纳：从具体事实归结出一般性规律，从样例中学习->规律->归纳学习。
			- 归纳学习：
				- 广义：从样例中学习
				- 狭义：从训练数据中学的概念（概念学习（研究少，应用少））
	- **假设空间**：eg:y=ax+b，a和b存在多种可能的集合就是**假设空间**，学习的目的就是找出最佳的线性代数，即最符合训练数据的a和b。
		- **版本空间**：在有限的训练集中，存在着多个最佳的，这个就是**版本空间**。即存在多个函数与训练的数据相对应。
		- **归纳偏好**：在版本空间中，不同的函数对于新预测的数据得出不同的结果，不同的算法有不同的选择，有两种偏好
			- **尽可能特殊**：适用情况尽可能少
			- **尽可能一般**：使用情况尽可能多
			- 如何选择：奥卡姆剃刀：**若有多个假设与观察一致，选择最简单那个**。

- **模型评估**：
	- 