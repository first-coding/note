**模型分类**：
	生成模型：**学习数据联合分布P(X,Y)**，可以生成新的数据样本
		GMM，朴素贝叶斯，HMM，GAN，VAE
	判别模型：**学习P(Y|X)，关注样本特征与类别**
		逻辑回归，SVM，决策树，随机森林，梯度提升树，神经网络
**评估标准**：
	分类
		**准确率**：$\frac{TP+TN}{TP+TN+FP+FN}$ ，**正确分类样本占总样本比例**
		**精确率**：$\frac{TP}{TP+FP}$，**分类为正且正确分类的占分类为正的比例**，FP为假阳性
		**Recall（召回率）**：$\frac{TP}{TP+FN}$ ，**分类为正且正确分类的占实际分类正的比例**，FN为假阴性
		**F1-score**：精确率和召回率的调和平均数，$F1=2*\frac{Precision*Recall}{Precision+Recall}$
		**ROC曲线和AUC**：
			ROC曲线：**以假阳性率为横坐标，以真正率为纵坐标绘制的曲线**
			AUC：ROC曲线下的面积，**值越大，模型性能越好**。
	回归
		**均方误差**：![[Pasted image 20241026222241.png]]
		**均方根误差**：![[Pasted image 20241026222251.png]]
		**平均绝对误差**：![[Pasted image 20241026222259.png]]
		**决定系数**：
		![[Pasted image 20241026222307.png]]
- LLM复读机问题：**生成文本时重复之前的内容**
	- 原因：存在多种原因，**模型对过去信息过度依赖、模型在处理长序列时的注意力机制失效**。
	- 解决方法：**数据增强**（通过增加训练数据的多样性、复杂性）、**模型改进**、**生成策略**（采用多样性策略，**抽样生成、引入随机性**）
- 大模型处理更长文本：**模型架构、加入内存机制（外部记忆/缓存）、分块（长文本分割更小的部分，之后分别处理）**
- 节省模型内存的方法：
	- **模型剪纸**：移除模型冗余结构和参数、减少内存占用
	- **知识蒸馏**：使用一个**大型教师模型**指导**小型学生模型**，学习大型教师模型，减少内存占用。
	- **量化**：高精度转低精度
	- **模型并行**：将大型模型分割多个设备上进行训练和推理
	- **数据并行**：将训练数据分割到多个设备上，每个设备训练模型的一个副本，减少单个设备的内存需求。
	- **动态批处理**：根据可用内存动态调整批量大小，以适应内存限制。
	