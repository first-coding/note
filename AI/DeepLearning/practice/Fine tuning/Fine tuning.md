![[Pasted image 20241019000228.png]]
1. **LORA**：
		- 只训练极小的参数，同时保持全量微调所能达到的性能。**通过在某些特定层/所有层添加两个低秩矩阵（矩阵的秩度量的矩阵行列之间的相关性）。**
	- 简单来说，**冻结一个预训练模型的矩阵参数，并选择用A和B矩阵来替代，在下游任务时只更新A和B**。![[Pasted image 20241018172824.png]]
	- 用数学来说，**通过修改线性层中的权重矩阵**，$$(ω+Δω)x=ωx+ABx$$其中，**ω为原始权重矩阵，Δω=AB**。即将**Δω进行低维分解**
	- 实现流程：
		1. 将$Y=ωx$转化为$Y=(ω+Δω)x$，**Δω是微调得到的结果**
		2. Δω进行**低维分解**$Δω=AB$
		3. 运用数据，训练出A和B即可得到Δω，**在推理的过程，直接把Δω加到ω上去，即无额外的成本**
	- **如果需要LORA适配不同的场景，可以尝试在进行LORA微调**
	- LORA存在多种不同的变体，**LORA-FA,VeRA,Delta-LoRA,QLoRA.......**
	- https://arxiv.org/pdf/2106.09685.pdf
	-  https://github.com/microsoft/LoRA
2. **Adapter**：
	- 在预训练模型**每一层（或者某些层）** 添加Adapter模块。**微调时冻结预训练模型主体，由Adapter模块学习特定下游任务的知识**，Adapter**只对新插入的Adapter层进行微调，而不是微调整个模型**。**显著减少了参数量和计算资源**
	- Adapter模块结构：
		- ![[Pasted image 20241018175436.png]]
		- Adapter由以下部分组成
			- **降维层（Down_projection）**：通过一个线性层对输入维度降低到较小的维度(**通常是瓶颈维度** )，**以减少计算量**
			- **非线性激活函数（Nonlinearity）**：降维后，**应用非线性激活函数来增强模型的表达能力**
			- **升维层（Up_projection）**：通过一个线性层将降维后的向量升维到原始维度
			- **残差连接（Residual connection）**：Adapter层通常与主模型采用残差连接，**即输入的特征不仅经过Adapter层，与原始特征进行相加**，**为了保持原模型的性能稳定**
	- 实现流程：
		- **冻结预训练模型的所有权重**：模型的大部分参数不会更新，以减少计算开销
		- **插入Adapter层**：在模型的不同层插入Adapter层
		- **微调Adapter层**：仅对这些插入的 Adapter 层的参数进行微调，学习特定任务的特征。
		- **保留Adapter层**：微调完成后，Adapter 层可以在不同的任务中共享使用，这使得一个模型可以方便地扩展到多个任务，而不需要重新训练整个模型。
	- **Adapter存在多个变体，Houlsby Adapter，Compacter，Parallel Adapter，AdapterFusion......**
	- https://arxiv.org/pdf/1902.00751
3. **Prefix-tuning（前缀微调）**：
	- 主要用于NLP任务，但也可以用于CV、语音，多模态等，**通过引入一个可学习的前缀，Prefix-tuning无需对模型的参数进行调整，通过调整前缀参数来适配特定的任务**
	- 可学习的前缀，**即PREFIX是一个可学习嵌入向量，而是矩阵。**
	- 实现流程：
		- **初始化前缀参数**：为输入的token添加一个前缀，**前缀的初始值通常是随机初始化的可学习参数。**
		- **任务微调**：使用特定任务的数据集训练模型，**冻结模型参数，只微调前缀**
		- **推理阶段**：在推理阶段，**前缀作为输入的组成部分被添加到每个输入序列前**，模型结合前缀生成任务特定的输出。
	- https://arxiv.org/pdf/2101.00190
	- https://github.com/XiangLi1999/PrefixTuning
4. **P-tuning**：
	- 通过学习输入序列的可学习嵌入来提高模型在下游任务上的表现
	- 在输入文本中注入一些**可学习的离散提示或虚拟标签**
	- 不同于 **Prefix-tuning 只调整前缀**，**P-tuning 直接对输入文本的 embedding 空间中的一部分进行微调**，使模型对特定任务产生更好的适应性。
	- 实现流程：
		- **确定任务和模型**
		- **构建提示模板**：P-tuning 的**核心思想是将虚拟 token（Prompt tokens）嵌入到输入文本的指定位置**，作为提示符来引导模型理解任务
			- 需要设计模板
				- **输入文本**
				- **可学习的虚拟token（虚拟是指不对应具体的词汇）**
		- **初始化虚拟的token的嵌入向量**：**初始化时不会与具体词语或 embedding 直接相关**，**通常被初始化为随机向量（或使用其他方式初始化），这些向量的维度与模型的词嵌入（embedding）维度相同。**
		- **模型输入与处理**：**将带有虚拟 token 的输入序列传递给模型**。虚拟 token 的嵌入向量会和实际输入的 token 嵌入向量**一起送入模型的前馈神经网络和自注意力机制**中
		- **模型训练**：训练过程，**虚拟的token嵌入向量可学习**
	- https://arxiv.org/abs/2103.10385
	-  https://github.com/THUDM/P-tuning 
- **P-tuning和prefix-tuning区别**：prefix-tuning是在**原先的token前面加上token**。P-tuning是**将虚拟的token嵌入到原先的token中**
5. **Prompt-tuning**：
	- Prompt-tuning 是通过在输入文本前或后添加一些**可学习的嵌入向量**，引导模型完成特定任务。整个模型的预训练参数保持冻结，仅微调这些提示符的嵌入向量。
	- 实现流程：
		- **选择预训练模型**
		- **设置prompt模板**：
			- **模板设计**：将输入文本与可学习的提示符嵌入向量 `[PROMPT]` 结合
			- `[PROMPT]` 不对应具体的词，**而是学习任务相关的上下文信息**
		- **提示符初始化**：`[PROMPT]` 可以随机初始化，例如一组大小为 `k` 的嵌入向量，假设 `k=2`，那么 `[PROMPT]` 可以表示为两个随机的 1024 维向量 `[P1, P2]`。
- **P-tuning和Prompt-tuning区别**：
	- P-tuning 的虚拟 token 是在输入文本中像普通 token 一样被处理
	- Prompt-tuning 更适合自然语言生成任务，如 GPT-3 的文本生成。
	- P-tuning 更适合自然语言理解任务，如情感分类、文本分类等。
	- **Prompt-tuning 优化的是提示符嵌入向量，而 P-tuning 优化的是虚拟 token 嵌入向量**
 6. **全量微调**：
	 - **全量微调就是预训练模型的参数都会更新**。
	 - 实现流程：
		 - **加载预训练模型**
		 - **准备数据**
		 - **调整超参数**
		 - **训练与推理**