- 数学基础：线性代数，概率论，高等数学（微积分）
- **基本概念**：
	- 优化：**通过改变自变量（x），最小化或最大化函数f(x)的过程。**
	- 在模型优化过程中，**目标函数/准则**：最大化或最小化的函数。当对目标函数进行最小化的时候，我们也称为**代价函数，损失函数，误差函数**。
	- 在对数据集进行建模过程中，**代价函数可以理解为对模型进行训练的时候和原先的标签差别有多大的函数**，**优化模型就是让这个代价函数最小化或者最大化**，**目标函数就是我们学习得到的一个函数，这个函数可以在数据集上有良好的表现。（在训练和优化过程中目标函数不一样）**
	- **激活函数**：可以理解为在神经网络中，**具有一定计算能力的神经元。决定在这个神经元中的输入与输出的关系。即输入一个值，通过这个具有激活函数的神经元之后的输出是什么**， 常见的激活函数有：**Relu，Sigmoid等等**。
		- **PS：sigmoid函数是一个大类，形似S的函数，函数连续，可导，有界。**，logistic sigmoid只是其中一种。
	- 在优化过程中，就是存在很多的方法，例如**梯度下降，随机梯度下降**等等。 ^ac5f63
		- 梯度下降：训练使用全部样本，每次迭代计算所有样本的梯度。
		- 随机梯度下降：训练随机选取样本，每次迭代计算少量样本的梯度。
		- 随机梯度下降和变种是机器学习中应用最多的优化算法
	- **凸和非凸**：
		- 凸函数：在该区间函数图象上的任意两点所连成的线段上的每一个点都位于函数图象的下方(或上方)。就存在一个极值点，这个极值点就是最值点![[Pasted image 20240307183439.png]]
		- 非凸函数：函数在该区间上有多个极值,即系统有多个稳定的平衡态。即存在多个极值点。![[Pasted image 20240307183450.png]]
		- 凸优化问题：目标函数和约束条件满足凸性质情况下的优化，凸函数的优化问题通常相对容易解决。
			- 目标函数是凸函数，即函数二阶导数为正
			- 约束条件是凸集：凸集（集合中任意两点之间的连线上的所有点也属于该集合）
			- 优化变量定义域是凸集：优化问题中涉及的变量所在的定义域也是凸集。
	- **正则化**：可以简单的理解为在损失函数f(x) 中加上了一定的项，从而降低模型过拟合的概率。
	- **饱和函数**：当输入值很大或者很小的时候，输出值趋于平缓的函数。这种函数会把梯度变得很小（即参数空间很小，因为趋于平缓没有太大的变化空间）
	- **泛函**：一个/多个函数到一个实数的映射，就是相当于说函数是自变量x，映射出来的一个实数就是因变量y。
	- **仿射变换**：几何中，对一个向量空间进行一次线性变化，并加上平移变换另一个向量空间
	- **线性变化**：指在两个向量空间之间保持向量加法和标量乘法的函数。
	- **协方差矩阵**：是衡量多个随机变量之间相关性的指标
	- **非归一化**：就是和不等于1的。
	- **异方差模型**：模型对不同的x值预测出y不同的方差，在传统的统计学中，假设输出值的方差是恒定的，即与输入值没关系。
	- **高斯混合**：多个高斯分布的线性组合。
		- ps：高斯混合输出在语音生成模型和物理运动中特别有效。
	- 对于函数f(x)具有左导数和右导数：
		- 左导数：紧邻在x左边的函数的斜率
		- 右导数：紧邻在x右边的函数的斜率
		- 可微：当函数在x处左导数和右导数都有定义并且相等，函数在x点处可微。
	- **约束优化**：在x的所有可能值中最大化或最小化一个f(x)不是我们所希望的，**x在某些集合S中找f(x)的最大值或最小值**。集合S内的点x被称为**可行点**。
	- **参数绑定**：指将**两个或多个参数设置为相同的值或者是彼此相关的函数**。通过参数绑定，模型将会减少参数的数量，从而减少了模型的复杂度，使得模型更容易训练和理解。
	- **参数共享**：指在**模型的不同部分使用相同的参数**。通常情况下，这些部分之间具有某种相似性，因此可以共享参数来提高模型的泛化能力并减少过拟合的风险。
	- **鲁棒性**：**在机器学习和人工智能领域中通常指的是模型或系统对输入数据的变化或干扰的抵抗能力**。一个具有良好鲁棒性的模型或系统能够在面对各种变化、干扰或攻击时保持稳定的性能或表现。
	- **算术平均**：是一组数字的总和除以数字的个数。它是最常见的平均数计算方法。算术平均用于描述数据集的集中趋势，它可以很好地反映出数据的总体水平。算术平均计算公式为：$$算术平均=\frac{所有数据总和}{数据的个数}$$
	- **几何平均**：是一组数字的乘积的N次根，其中N是数字的个数。几何平均常用于描述一组数据中的相对变化率或增长率。它通常用于处理一些比率、指数或百分比数据，比如利率、收益率等。几何平均计算公式为：![[Pasted image 20240330150726.png]]
	- **几何平均和算术平均都是描述一组数据中心趋势的统计量**。
	- **对抗样本**：就是对原先数据集进行细微改动（人眼看不出来的程度），但却引起了机器学习模型产生错误的输出。
	- **对抗训练**：是一种训练机器学习模型的方法，**旨在提高模型对对抗样本的鲁棒性**。对抗训练通过在训练过程中引入对抗性扰动来训练模型，使其更加抵抗对抗样本的攻击。
	- **流形学习**：**是一种用于理解高维数据结构的机器学习方法。它的基本思想是假设数据分布在一个低维流形（manifold）上，而不是在整个高维空间中均匀分布**。流形学习算法试图从**数据中学习这个潜在的低维流形，并将数据映射到一个更低维度的空间中**，以便更好地描述数据的结构、减少数据的维度、可视化数据以及提高机器学习模型的性能，**指的是一类机器学习方法，这一类机器学习方法中有很多种**。
		-  **正切传播算法**。
	- **流形假设（Manifold Hypothesis）**：是指在高维空间中的数据通常分布在一个低维流形上。简单来说，流形假设认为数据虽然存在于高维空间中，但实际上只占据了一个低维的子空间。
		- **流形假设的切面距离算法**是一种用于测量数据点之间相似度的方法
			- 该算法的基本思想是在**局部切面上度量数据点之间的距离**，而**不是在整个高维空间中进行度量**。这样做的原因是假设数据点在局部区域内都位于低维流形上，因此使用局部切面来度量距离更能准确地反映数据点之间的**相似性（理解数据的内在结构和关系，从而实现更有效的数据处理和分析）**。
	- **预训练**：**通常是指在一个大规模数据集上训练一个通用的模型**，例如一个大型的神经网络，而不是针对某个特定的任务。这个预训练过程旨在**让模型学习到数据的一些通用模式或特征**，使得模型具有**更好的初始参数**，能够**更快地收敛**到合适的解。
	- **微调**：微调（fine-tuning）是**指在预训练模型的基础上**，使用**特定任务的数据集对模型进行进一步训练的过程**。
	- **范数**：度量向量空间中向量长度。eg：
		- ![[Pasted image 20240411141305.png]]
	- **鞍点**：梯度为零的点。
		- 低位空间中，局部极小值很普遍，但是在高位空间中，极小值很罕见，而鞍点很常见。**因为高维空间中鞍点的激增解释了为什么在神经网络训练过程中二阶方法无法成功取代梯度下降**。因为牛顿法目标是寻求梯度为零的点，所以在高维空间会陷入一个鞍点，所以需要**二阶无鞍牛顿法**。
	- **参数**：模型参数是模型内部的可学习变量，它们的值是通过训练数据进行学习得到的。简单来说，f(x)=ωx+b，函数可以修改的值就是参数。ω和b。
	- **超参数**：超参数是在模型训练之前手动设置的参数，它们控制着模型的学习过程和结构。这些参数通常不是通过训练数据学习得到的，而是需要通过实验和验证来选择最佳的取值。简单来说函数修改不了的值就是超参数，例如：神经网络的层数，学习率，正则化参数.......
	- **正定矩阵**：M为n阶方阵，对任何非零向量Z，存在$z^TMz>0$,M就为正定矩阵。
	- **先验概率分布**：在进行观测/实验之前，基于以往知识/经验得到的概率分布。
	- **Gabor函数（科普知识）**：![[Pasted image 20240416200000.png]]Gabor函数的特点是它可以在空间域和频率域同时具有良好的局部化特性，这使得它在分析局部特征时非常有用。
- **优化和训练**：
	- ![[Drawing 2024-03-08 17.26.19.excalidraw]]优化算法的目标就是让模型更优，那就存在一些算法来进行一系统的操作（即一堆数学方面的转换），就比如**梯度下降算法（不仅是训练算法也是优化算法）**。**正则化**也是一种优化算法，目的是为了防止模型过拟合，但是**正则化并不是训练算法**。
	- **训练算法**：在数据集中进行学习，得到对应的权值ω，然后得到一个模型。使这个模型可以更好的拟合现有的数据集并预测新的数据。
	- **反向传播和其他微分算法**：
		- **前向传播**：将输入数据通过神经网络各层次的计算，得到模型的输出。
		- **计算代价函数**：使用模型的输出和真实标签的差异来计算代价函数J(θ) 的值，代表了模型的预测误差。
		- **反向传播**：根据代价函数的值，使用反向传播算法来计算梯度，并利用**梯度下降等优化算法更新神经网络参数θ来减小代价函数的值**，从而优化模型性能。
			- **递归使用链式法则实现反向传播**：[[深度学习（花书）#^6f645c]]
			- **一般化的反向传播**：符号微分，用于计算复杂计算图中某个标量输出相对于输入的梯度。**这个方法通常用于推导和分析梯度的形式，而不是在实际计算中使用。**： ^7d08ea
				- **设置初始梯度**：首先，将关于输出标量z的梯度设置为1，即dz/dz=1。这是因为z对于自身的梯度是1，这是链式法则的基本规则。
				- **计算Jacobian矩阵**：然后，对于产生z的每个操作（例如加法、乘法等），计算其对应的Jacobian矩阵。**Jacobian矩阵描述了每个操作对于输入和输出之间的关系，它包含了每个输入变量对于每个输出变量的偏导数。**
				- **反向传播**：从输出节点开始，沿着计算图的路径向后传播。**对于每个操作，将上游梯度乘以对应的Jacobian矩阵**，得到下游节点的梯度。这样，**沿着计算图的路径反复进行，直到到达输入节点位置。**
				- **累积梯度**：在反向传播的过程中，将**得到的梯度与之前的梯度相乘**，以便将**每个路径上的梯度相加**。这样可以累积所有可能路径上的梯度贡献。
				- 得到梯度。
			- **反向传播仅仅用于计算梯度的方法**，（计算出来的梯度可以用另一种训练算法**比如梯度下降**，通过使用梯度来进行学习）
				- **计算图**：将计算过程化成图像的方法。可以更准确的描述一些算法。
			- **即一种计算导数的链式法则的算法，使用高效的特定运算顺序** ^6f645c
				- 通过已知的微积分求导的链式法则将变量转成向量就变成![[Pasted image 20240317152805.png]]**Jacobian matrix**:![[Pasted image 20240317152910.png]]即输入和输出都为向量的函数的所有偏导数
				- 可以知道，向量x的梯度可以通过Jacobian matrix$\frac{α_y}{α_x}$和梯度相乘得到。**反向传播算法就是每一个这样的Jacobian和梯度的乘积操作组成。**
				- ![[Drawing 2024-03-17 15.41.15.excalidraw]]
				- **反向传播算法可以自动生成梯度，当梯度计算图过大的时候，就会方便许多。**
		- **其他微分**：
			- **自动微分**：如何通过算法方式进行导数计算，（反向传播算法只是其中一种）
				- **反向模式累加**：
					- 反向模式累加从函数的输出变量开始，逐步计算中间变量相对于输出变量的导数，直到得到输入变量的导数。
					- 这种方法对于有多个输入的函数比较适用，因为每个输入的导数可以从输出开始反向传播计算。
				- **前向模式累加**：
					- 前向模式累加从函数的输入变量开始，逐步计算中间变量的导数，直到得到最终输出变量的导数。
					- 这种方法对于有多个输出的函数比较适用，因为每个输出的导数都可以从头开始独立计算。
			- **高阶微分**：
				- Hessian矩阵：![[Pasted image 20240317160006.png]] 函数存在多维输入，二阶导数也有很多，将这些二阶导数合并成一个矩阵就是**Hessian矩阵**,Hessian矩阵等价于梯度Jacobian矩阵
				- 典型的深度学习方法时使用**Krylov方法**：
					- 用于执行各种操作的一组迭代技术。（**操作包括像近似求解矩阵的逆或者近似矩阵的特征值/特征向量等**）
	- **优化算法**：通过训练得出的模型可以并不是最优的模型，我们需要让这个模型更好的拟合现有的数据并预测新的数据。可以简单的理解为将模型的**性能度量**最小化或最大化。
	 - **最大似然原理**：在已知样本的情况下，最合理的参数值是让样本出现概率最大的参数值
		- **传统的方法：直接预测目标变量 y 的完整概率分布。例如，在分类任务中，模型会预测每个类别的数据出现的概率。**
			1. 初始化参数(根据经验，随机化等等方法)
			2. 计算观察数据序列x在参数p下的似然函数P(X|p):
				-  $$P(x|p)=p*p$$
			3. 更新参数p，使得似然函数最大化
				-  $$p=P(X)/P(X|p)$$ 
			4. 重复2和3，直到参数p收敛。
		- **简化方法：预测目标变量 y 在给定输入变量 x 条件下的某种统计量，例如均值、方差或中位数。例如，在回归任务中，模型会预测目标变量的期望值。**
			1. 初始化参数(根据经验，随机化等等方法)
			2. 计算观察数据序列x中所有条件统计量 P(xᵢ | xᵢ₋₁, p)。
			3. 更新参数 p，使得条件统计量 P(xᵢ | xᵢ₋₁, p) 与观测数据序列 X 中的实际条件统计量一致。 
			4. 重复2和3，知道参数p收敛。
		- **最大似然估计**：基础最大似然原理的参数估计方法，即可以简单的理解为模型中参数的估计方法（并选择合理的模型参数，并不是没有任何理论依据的进行模型参数的调整）。**可以理解为概率分布下取值的逆运用，概率分布下取值是通过每个位置的概率随机生成样本，而最大似然估计就相当于知道了样本量，从而去求这个概率分布**。
		- **通过最大似然可以导出代价函数**
			- 在最大似然中代价函数就是**负对数似然函数（但可以在使用最大似然进行模型的训练的时候，不采用这种代价函数，也可以自己手动选择代价函数）**。
			 1. 定义似然函数（描述特定参数下，观测数据出现概率），**衡量了观测数据与模型的拟合程度**$$L(θ | x,y)=P(y|x,θ)$$其中左边的就是似然函数，θ 是模型参数，x观测的数据（可以理解为特征向量），y即特征向量x的标签。
			 2. 定义对数似然函数$$l(θ | x, y) = log L(θ | x, y)$$
			 3. 定义代价函数，使用**负的对数似然作为代价函数**$$J(θ) = -l(θ | x, y)$$
			 4. 训练模型，通过优化算法（梯度下降）求出代价函数最优解。
			- 可以理解为这个最大似然就是一套体系流程。
			- PS：这个最大似然只是其中的一种训练方法，还存在着**梯度下降，最小二乘法，贝叶斯估计等**
			- 在梯度下降训练算法中，梯度下降可以理解为一种经验算法，需要手动的进行损失函数选择。
	-  **正则化**：
		- 设计来减少测试误差（可能以增大训练误差为代价），这些策略统称**正则化**。避免过拟合的。
		- **权重衰减**：通过在损失函数中增加一个惩罚项，减少权重的大小，从而降低模型复杂度的方法。
		- $\tilde{J}(θ;X,y)=J(θ;X,y)+αΩ(θ)$ ，分配不同的α对应不同的正则化惩罚，**α越大，对应正则化惩罚越大**。
		- 两种方法：
			- 对机器学习模型添加限制参数值的额外约束。
			- 增加额外项对参数值进行软约束。
				- **L2参数正则化**：令$Ω(θ)=\frac{1}{2}||ω||^2_2$ ,让权重更加接近原点。**也称岭回归和Tikhonov正则**。  
				- **L1正则化**：令$Ω(θ)= ||ω||_1=\sum\limits_{i}|ω_i|$ 即各个参数的绝对值之和
				- L1会产生更加稀疏的解（最优值中的一些参数为0）。L2则不会。
		- 神经网络中，参数包括每一层仿射变换的权重和偏置，只对**权重进行正则化惩罚**，**对偏置不做正则化惩罚**。
		- **正则化会在显著减少目标函数的方向的参数保留会更好，对于无助于减少目标函数的方向会在正则化中衰减掉**。
		- 总的来说，**正则化就是在训练误差和测试误差中寻找一个平衡点**。通常会与梯度一起对模型进行优化
		- **在希望对模型参数的范围或者形式进行更严格的控制时，我们需要对正则化后的目标函数进行约束**
			- 增加一个惩罚项
			- 显式约束（修改特定的参数）
		- **数据集增强**：可以提高模型的泛化能力（但是要根据需求来说），**即创建新的假数据**，eg：
			- 图像，可以进行旋转、缩放、平移等操作得到大量新的数据集（但是对于特定的需求有些操作就不可以，比如识别6和9，这样就不可以旋转）
			- 语音，可以加入噪声进行训练，可以在输入层中也可以在隐藏层中。
			- 对于某些模型来说，向输入单元添加方差极小的噪声等于对权重施加一个惩罚项
				- 向隐藏层输入噪声会更好，[[深度学习（花书）#^8c1013|Dropout]]
			- 另一种是把噪声加入到权重中。
		- **多任务学习**：通过合并几个任务中的样例（可以看成对参数施加软约束）**是一种训练模型的方法，是一种通用的方法论，旨在提高模型的泛化能力、效率和性能。**
		- **提前终止**：存在这样一种情况，当训练有足够的表示能力甚至过拟合的大模型时候。就会出现**训练误差逐渐降低，但是验证集的误差再次上升**。这时候为了保证验证集的误差最小。我们需要用到提前终止的算法
			- 当每次验证集的误差有所改善的时候，存储参数副本。当误差在一定的循环次数没有进一步改善，算法终止，返回验证集误差最低的参数
		- **惩罚神经网络中的激活函数，稀疏化激活单元。** 间接的对模型参数施加惩罚。
			- **含有隐藏单元的模型在本质上都可以变得稀疏**。
		- **Bagging**：通过结合几个模型减低泛化误差的技术，**分别训练几个不同的模型，然后让所有模型表决测试样例的输出。**
		- Bagging 主要关注于使用**同一种基本学习算法**，但在不同的训练数据子集上训练多个模型，这些子集是通过**有放回的抽样**（Bootstrap）获得的。这意味着 Bagging 使用的是同一种类型的基本学习算法，但是在不同的子集上训练它们，以增加模型的多样性。
		- **模型平均**：**是一种将多个模型的预测结果进行平均或加权平均的技术。**
		- 可以使用**同一种或不同种类的学习算法**，然后对它们的**预测进行加权平均**。这些权重可以通过验证集上的性能来确定。这种方法旨在结合不同类型或同一类型的模型以提高性能。
		- **Dropout**：一种常见的用于深度神经网络的正则化技术。**可以理解为是Bagging的近似，对于整个神经网络随机将一些神经元的输出置为0，构建不同的子模型（共享模型参数）** ^8c1013
			- PS：**Dropout通常用于隐藏层**，只有在**训练**的时候用的是**子模型（即不是完整的神经网络）**。而在模型的**预测为了得到稳定的结果，用的是完整的神经网络模型**
		- Bagging和Dropout推断：
			-  Bagging：每个模型i产生一个概率分布$p^{(i)}*(y|x)$ 。 多个模型集成城的预测由这些分布**算术平均算出**$$\frac{1}{k}\sum_{i=1}^{k}p^{(i)}(y|x)$$
			- Dropout也是通过计算**每个掩码定义的概率分布的算术平均得到** $$\sum_{u}p(u)p(y|x,u)$$p(u)是训练时采样u的概率分布，**但是因为存在着多达指数级的项，要么简化神经网络结构（但是无法知道是否可行，如今也没答案），要么近似（通几何平均近似计算）。**
		- **对抗训练，提高模型对对抗样本具有更好的鲁棒性**
	- **学习与纯优化**：
		- 用函数f(x)=ωx+b来说，
			- **学习就是通过数据不断的计算算出ω，然后找到一个ω让他和数据的差别最小**。
			- **纯优化就是关注函数本身，直接通过数学方法或优化算法直接求出最好的ω。**
		- **在训练过程中，关注性能度量p，学习是间接的优化p，我们希望通过降低代价函数来提高p**，纯优化是最小化目标本身。
		- **经验风险**：模型在训练数据集的平均损失，**度量平均意义下模型预测效果的好坏**。
			- ![[Pasted image 20240408182250.png]]
			- **经验风险最小化**：最小化平均训练误差的训练过程。
			- 经验风险最小化很容易导致过拟合，会简单的记住训练集，导致泛化能力不好。**在深度学习中很少使用经验分线最小化**。
		- **代理损失函数**：当目标函数非凸、不连续时，数学性质不好，优化起来比较复杂，这时候需要使用其他的性能较好的函数进行替换。eg:使用负对数似然损失函数进行替换。
		- **批量算法和小批量算法**：
			- 机器学习算法目标函数通常可以分解为训练样本的求和，优化算法在计算参数的时候每一次更新仅使用整个代价函数中一部分项估计代价函数的期望值。
				- 使用**整个训练集的优化算法**称为**批量/确定性梯度算法（在一个大批量中同时处理所有样本）**
				- 使用**单个样本的**优化算法称为**随机/在线算法**（在线指的是从连续产生样本的数据流中抽取样本的情况，**而不是从一个固定大小的训练集遍历多次采样** ）。
				- **大多数深度学习的算法介于两者之间**，使用**一个以上而又不是全部的训练样本**，称为**小批量/小批量随机**，通常称为**随机方法**。
					- **批量大小越大，训练时间会降低，提高稳定性。可能会导致欠拟合。** 会计算更精确的梯度估计，但是汇报却小于线性。
					- **批量大小越小**，**模型泛化能力下降。可以会导致过拟合**。当太小的话难以使用多核架构，当小于绝对最小批量的话并不会减少计算时间。
					- 内存消耗与批量大小成正比。
					- **某些硬件上使用特定的大小的话，会减少运行时间，尤其在用GPU的时候（使用2的幂数作为批量大小会获得更少运行时间，32~256）。**
					- **随机方法需要进行随机抽取，希望样本之间都是独立的。如果同一批量里面都是同一个样本，会导致模型过拟合。**，所以要对数据集进行打乱，最好对数据集进行**均匀抽样**（但对于特别大的数据集，这个不现实）。很多小批量随机梯度下降实现都会打乱数据顺序，**然后多次遍历数据集来更新参数**（但数据量过大的话，就**可能每个样本就用一次/不完全使用训练集（这个时候就要考虑欠拟合了）**）
		- **神经网络优化挑战**：
			- 我们总是会谨慎得设计目标函数与约束，确保优化问题是凸（凸函数）的，从而去避免一般优化问题的复杂度。**但是也会遇到非凸的情况，对于凸优化也存在部分问题**
				- 优化凸函数，最突出的问题就是Hessian矩阵H的病态（**输入微小的误差导致输出的巨大改变** ，一般认为存在神经网络训练过程中，**体现在随机梯度下降会卡在某个情况**），可以通过牛顿法进行解决。但是运用在神经网络需要很大的改动。
			- **模型可辨识性**：即训练集是否可以唯一确定一组模型参数，如果可以即说可辨认，反之就是不可辨认（因为这个不可辨认产生局部极小值都有相同的待代价函数值，反过来说就是**神经网络代价函数具有非常多甚至无限多的局部极小值**，那么则很难基于梯度的优化算法进行优化模型）。
			-  **悬崖和梯度爆炸**：
				- 悬崖：**神经网络模型的损失函数曲面上存在梯度变化极大的一块区域**。
					- 有可能因为几个较大的权重相乘导致的。
					- 梯度变化极大会出现训练不稳定，难以收敛。
				- **梯度爆炸**：在神经网络训练过程中，**梯度值变得过大**，导致模型参数更新过快，从而使模型无法收敛到最优解。导致模型难以收敛。
			- **长期依赖**：**模型需要从远处的输入序列中获取信息才能预测当前输出**。
				- 在传统的RNN中，**由于梯度消失和梯度爆炸问题，模型难以学习长期依赖关系**。
				- **梯度消失**：在 RNN 中，随着时间步的增加，梯度会不断缩小，最终导致梯度消失。梯度消失会使得模型难以学习远处的输入序列中的信息。
				- **梯度爆炸:** 在 RNN 中，随着时间步的增加，梯度也会不断增大，最终导致梯度爆炸。梯度爆炸会使得模型参数更新过快，从而导致模型无法收敛到最优解。
				- 表现形式就是**模型忘记很久之前的内容**。
				- 通常会出现RNN中。eg：
				- 通常可以用双向RNN、LSTM网络解决和注意力机制解决。
					- ![[Pasted image 20240411151150.png]]
			- **非精确梯度**：存在一种情况，目标函数难以最小化，在目标函数难以最小化的情况下，梯度也是难以处理的，只能使用**近似梯度**。
			- **局部和全局结构间的弱对应**：**局部结构的变化并不能保证全局结构也发生相应的变化**。
			- ps：**有结果表明，为神经网络设计的任何优化算法都有性能限制，但是通常不会影响神经网络在实践中的运用**。
		- **参数初始化策略**（模型的参数进行初始化，不是超参数进行初始化）：
				- **基于分布的初始化策略**：使用概率分布随机抽取来初始化参数。
				- **基于正交化的初始化策略**：这些策略旨在确保模型参数之间的正交性。**Gram-Schmidt正交化和随机正交矩阵初始化。**
				- **基于特定属性的初始化策略**：这些策略根据网络结构、激活函数的特性或者数据的属性来选择合适的初始化方法。**Xavier 初始化、He 初始化等。**
				- **基于稀疏性的初始化策略**：这些策略旨在将参数初始化为稀疏矩阵，从而减少模型的参数量。
				- **基于领域知识的初始化策略（启发式）**：根据经验来进行初始化。
				- **自适应初始化策略**：根据网络结构和激活函数的特性动态地选择合适的初始化方法。
		- **基础的算法**：
			- **[[深度学习（花书）#^ac5f63|随机梯度下降和梯度下降。]]**
				- **动量**：随机梯度下降算法的优化，旨在加速学习，在高曲率、小但一致的梯度、带噪声的梯度。主要目的解决两个
				- Hessian矩阵的病态条件和随机梯度的方差
				- 动量方法和随机梯度下降算法最大区别：
					- 在于梯度方向和步长的问题。
					- 动量方法梯度方法考虑当前和之前的梯度方向和步长，随机梯度下降算法只考虑当前梯度的方向。之前步长是**梯度范数乘以学习率**，动量步长取决于**梯度序列的大小和排列**。
					- **Nesterov动量**：动量算法的变种，与动量算法相比，梯度更新方法的计算不同。
			- **自适应学习率算法**：
				- **AdaGrad**：
					- 计算梯度
					- 累计平方梯度
					- 计算更新，![[Pasted image 20240413130031.png]]
					- 应用更新，![[Pasted image 20240413130048.png]]
					- ![[Pasted image 20240413130301.png]]
				- **RMSProp**：
					- 更新学习率的方法不同![[Pasted image 20240413130130.png]]
					- ![[Pasted image 20240413130323.png]]
				- **Adam**：
					- ![[Pasted image 20240413130239.png]]
				- **这三种算法都是在计算学习率变化的时候存在差别。**
		- **二阶近似方法**：
			- **牛顿法**：应用于神经网络的训练。
				- 牛顿法是基于二阶泰勒级数展开在$θ_0$ 附近近似$J(θ)$ 的优化方法。![[Pasted image 20240413124834.png]]H是J相对于θ的Hessian矩阵在$θ_0$ 的估计。求解这个函数的临界点，得到**牛顿参数更新规则**：![[Pasted image 20240413124941.png]]
				- **对于局部的二次函数（具有正定的H），用$H^-1$ 调整梯度，牛顿法会直接跳到极小值**
				- **对于凸的但非二次的（有高阶项），更新是迭代的。**
				- **对于非二次的表面，Hessian矩阵保持正定，牛顿法就能迭代运用**。
					- 计算梯度
					- 计算Hessian矩阵
					- 计算Hessian逆矩阵
					- 计算学习率更新
					- 学习率更新。
					- ![[Pasted image 20240413130359.png]]
				- 牛顿法训练大型神经网络存在显著计算负担
					- Hessian矩阵元素数目是参数数量平方，还需要计算逆矩阵。
				- **只有参数很少的网络才会运用牛顿法进行训练**。
			- **共轭梯度**：通过迭代下降的**共轭方向**有效避免Hessian矩阵求逆计算方法。![[Pasted image 20240413134755.png]]
			- BFGS：牛顿法主要计算难点在于计算Hessian逆$H^-1$ ，BFGS使用矩阵$M_t$ 近似逆。
				- 因为BFGS需要存储Hessian逆矩阵M，所以O(n^2)事件，所以BFGS不适用于大多数具有百万参数的现代深度学习模型。
		- **优化策略和元算法**：
			- **批标准化**：是一个自适应的重参数化的方法，试图解决训练非常深的模型困难。
				- $H'=\frac{H-μ}{σ}$  $μ=\frac{1}{m}\sum_iH_i$ $σ=\sqrt{δ+\frac{1}{m}\sum_i(H-μ)^2_i}$  μ是每个单位均值的向量，σ是每个单元标准差的向量，H是需要标准化的某层的小批量激活函数，δ是一个常数，强制避免遇到$\sqrt{z}$的梯度在z=0处未定义的问题。
				- 即对每个特征进行归一化，使其均值接近0，标准差接近1。
				- 将分散的数据进行统一，**解决训练过程中梯度消失和梯度爆炸的问题**，优化神经网络各层之间的输入分布。使得网络在**训练过程中更加稳定**。此外，批标准化还有助于**加速模型的收敛速度，允许使用更高的学习率，从而加快模型训练的过程。**
			- **坐标下降**：
				- 通过单个变量x去最小化f(x),对每个变量都这样，就可以到达局部极小值。![[Pasted image 20240413143815.png]]**在每次迭代中，坐标下降算法只更新一个变量，而将其他变量保持不变。这使得算法在高维空间中更容易收敛，并且可以应用于不可微分的目标函数。**
			- **Polyak平均**：
				- 通常用于随机梯度下降（SGD）等优化算法中，旨在**提高参数更新的稳定性和收敛速度**。
				- 通常会在**模型的训练过程中保存每次参数更新的历史信息**，然后**计算这些历史参数的平均值，作为最终的模型参数**。
			- **监督预训练**：是一种用于训练深度神经网络的技术
				- 在某种程度上可以说是先训练简单的模型，然后在此基础上进行进一步的微调或增加层数等操作来解决更复杂的问题。
				- **贪心算法**：将问题分解多个部分，独立在求出局部最优解，然后结合起来，**不能保证最终的到一个最佳的完整解**，但是可以接受。之后**精调**，运用**优化算法搜索全问题的最优解**，**可以极大加速算法，提高寻到的解的质量**。
					- 以先前训练的隐藏层输出作为输入。
					- 将先前训练的MLP（多层感知机）**输出和原始输入**，作为每个附加阶段的输入。
				- **FitFets**：是一种**神经网络架构**，旨在促进不同网络之间的知识转移。它们的设计旨在解决将**大型、计算密集的教师网络**的知识转移到**更小、更高效的学生网络的挑战**。学生网络往往更深更窄。
					- 通过引入**额外的损失项**，使得学生网络在训练过程中尽可能地**模仿教师网络的中间层激活**，从而促进了知识的转移和蒸馏（distillation）。
					- **知识蒸馏**：通过从一个**大型、复杂**的模型（教师模型）中提取知识，并将其传递给一个**较小、更简单**的模型（学生模型），从而实现**性能和计算效率的平衡。**
						- 让小模型模仿大模型的输出（soft target），从而让小模型能获得大模型一样的泛化能力，这便是知识蒸馏，是模型压缩的方式之一。
				- 通常两个步骤：
					- **预训练阶段**：在大规模的未标记数据集上，使用**无监督学习方法**（如自编码器、受限玻尔兹曼机等）或**半监督学习方法**（如自监督学习）来训练一个浅层的模型（通常是前几层），得到**参数的初始值**。
					- **微调阶段**：将**预训练好的模型作为初始参数**，然后使用带标签的数据集（**监督学习）来对整个模型进行微调**，通常是通过**反向传播算法来调整模型参数**，以**最小化损失函数**。在微调阶段，还可以**增加模型的深度**（即增加更多的层），从而**提高模型的表达能力**。
			- **设计易于优化的模型**：使用易于优化的激活函数。比如Relu，这些单调模型上上下下的激活函数。
			- **延拓法**：对局部进行优化不代表全局也优化了。**延拓法用于克服局部极小值的问题，并不常见。**
				- 通过构造一系列具有相同参数的目标函数，目标是**最小化代价函数$J(θ)$** 。然后不断的最小化这些一系列代价函数{$J^{(0)}...... J^{(n)}$} ，最终最小化$J(θ)$ 。
			- **课程学习/塑造方法**：先学习简单的概念，然后逐步学习依赖于简单概念的复杂概念。
				- **随机学习**：简单的和困难的混合在一起，随机提供给学习者。
	- **优化简单来说就是寻找神经网络上的一组参数，可以降低代价函数**。
	- **大多数优化技术是一般化的模板，可以特定产生算法/并入到不同算法中。**
- **架构**：网络的整体结构（应该有多少个单元，这些单元之间怎么连接，以及激活函数选择......）
	- **更深层的网络通常能够对每一层使用更少的单元数和更少的参数，并且更容易泛化到测试集，但是通常难以优化**。
	- **万能近似定理**：一个前馈神经网络，如果具有**线性输出层**和至少一层具有任何一种 **“挤压“性质的激活函数**（**logistic sigmoid激活函数**）的**隐藏层**，给予网络足够数量的隐藏单元，可以以**任意精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数**，关于Borel可测只需要知道，定义在$R^n$的有界闭集上的任意连续函数是Borel可测的，所以可以用神经网络来近似。
		- 万能近似定理意味着：无论我们试图学习什么函数，一个大的MLP（多层感知机）一定能够表示这个函数。（**可以保证MLP可以表示这个函数，但是无法保证训练算法可以学习到这个函数** ）
			1. 用于训练的优化算法可能找不到用于期望函数的参数值。
			2. 训练算法可能由于过拟合选择错误的函数。
		- 总的来说，可以用前馈神经网络表示任何函数，但是网络层可能特别大无法实现，还可能无法正确学习和泛化。**大多数情况都是使用更深的模型去减少期望函数所需要的神经元的数量，减少泛化误差**。
		- **存在一种函数族，当神经网络的深度大于d的时候，就可以无限的近似**，但是当**小于或等于d**的时候就需要n的指数级的隐藏单元。
			1. 不与连续可微的神经网络类似的机器学习模型中出现
			2. 关于逻辑门电路
			3. 具有非负权重的线性阈值单元
			4. 连续值激活的网络
		- 大部分情况下，神经网络的深度越深，在合适的任务和数据集中，准确率会越高。
	- **输出单元**：基于不同任务和任务符合的概率分布进行输出层函数的激活函数
		- 用于高斯输出分布的线性单元，高斯分布就是正态分布。
			- 输出单元基于仿射变换的输出单元，称为线性单元
			- 给定特征，线性输出单元层产生一个向量$$θy = W^Th+b$$
			- 当存在两个前提条件时：
				1. 模型的输出服从条件高斯分布$$p(y|x)= N(y; μ(x), Σ)$$μ(x)是条件均值，Σ协方差矩阵（高斯分布的协方差矩阵是一个对称矩阵）
				2. 只适用于线性关系的
				- 当存在这两个前提条件时**线性输出层常常用来产生条件高斯分布的均值** 
			- 当存在两个前提条件：
				1. 模型的输出服从条件高斯分布$$p(y|x)= N(y; μ(x), Σ)$$
				2.  误差项 (y - μ(x)) 服从均值为 0 的高斯分布,即模型的误差应该随机分布在 0 的周围，且正负误差出现的概率大致相等。
				- 最大化对数似然函数等价于最小化均方误差。
			- 最大似然框架让学习高斯分布的协方差矩阵更加容易
				- 似然函数：L(μ, Σ) = ∏ᵢ p(xᵢ | μ, Σ)，通过最大似然估计即可求出协方差矩阵Σ。
		- 用于伯努利分布输出分布的sigmoid单元：当需要预测二值型变量y的值。 ^800fd7
			- sigmoid输出单元定义为$\hat{y}=σ(ω^Th+b)$ 可以理解为两部分内容，线性层$z=ω^T+b$ 和sigmoid激活函数将z转化为概率。
			- logistic sigmoid函数:$$f(x)=\frac{1}{1+exp(-x)}$$exp是取指数的意思。即$exp(x)=e^x$![[Pasted image 20240310152721.png]]sigmoid函数在变量取绝对值非常大的正值或负值会出现饱和状态，函数图像会变得很平滑，对输入的微小改变不敏感。
			- softplus函数：![[Pasted image 20240310153654.png]]，可以用来产生正态分布的β和σ，因为它的范围是（0，∞）.![[Pasted image 20240310155007.png]]
		- 用于Multinoulli输出分布的softmax的单元：用于一个具有n个可能取值的离散型随机变量的分布。
			- 最常用在分类器的输出，来表示n个不同类上的概率分布。
			- 比较少见的是softmax函数在模型内部使用。 
			- 可以通过sigmoid函数控制的Bernoulli分布去进行推广到**存在n个值的离散型变量的情况**。
				- **确保每个元素$\hat{y_i}=p(y=i|x)$每个$\hat{y_i}$元素介于0和1之间，还要确保全部$\hat{y_i}$ 的和为1 **
				- 可以通过先对一个线性函数$z=W^Th+b$，$z_i=logP(y=i|x)$，在通过softmax函数对z指数化和归一化得到$\hat{y}$，得到$sofxmax(z)_i=\frac{exp(z_i)}{\sum_jexp(z_j)}$  exp代表指数化。
		- 除了常见的线性，simoid和softmax输出单元最常见，还存在着其他的输出单元，**可以通过最大似然原则进行几乎任何种类的输出层设计一个好的代价函数提供指导**。
	- **隐藏单元**：如何选择隐藏单元类型？（隐藏单元在模型的隐藏层中，即隐藏层中的激活函数怎么选择）
		- ReLU：$f(x)=max(0,x)$ ，当输入x为正数，输出本身x，否则就为0。是隐藏单元极好的默认选择，也通常用在隐藏单元中。
			- PS：ReLu在x等于0处不可微，因为可微才可以通过基于梯度的学习算法进行训练或优化。**但是因为神经网络训练算法通常不会达到代价函数的局部最小值**，而只是显著减少它的值。
		- Relu扩展：基于$z_i<0$时使用一个**非零的斜率**$α_i:h_i=g(z,α)_i=max(0,z_i)+αmin(0,z_i)$ 
			- **绝对值整流**：固定$α_i=-1$得到g(z)=|z|。
				- ![[Pasted image 20240314171617.png]]
			- **渗漏ReLu**：将$α_i$固定成一个类似0.01的小值.![[Pasted image 20240314171827.png]]
			- **PReLu**：将$α_i$作为学习参数。
				- ![[Pasted image 20240314171948.png]]这里的α不是固定的值，而是可以通过训练集数据拟合得到的，每个神经元的α可能不一样。
			- **maxout单元**：$f(x)=max(z_1,z_2,...,z_k)$  $z_i=ω_i^T+b_i$  k是maxout单元划分的组数 ，$ω_i$是权重向量，$b_i$是偏置。**Maxout单元的输出 f(x) 是经过这些线性变换后的最大值，因此可以看作是对输入x 的非线性映射。** 通常作为隐藏层的激活函数。
				- maxout单元具有冗余可以抵抗**灾难遗忘和噪声**。
				- **灾难性遗忘**：是指当模型接收到**新数据或进行新任务**时，会**忘记之前学习到的知识或特征**。这可能会导致模型性能下降，因为模型过于专注于新数据或任务，而忽略了以前学到的有用信息。
		- logistic sigmoid与双曲正切函数：
			- logistic sigmoid激活函数见$g(z)=α(z)$[[深度学习（花书）#^800fd7|logistic sigmoid]]
				- sigmoid单元在大部分定义域内都饱和，仅当z接近0时，才对输入敏感。因为大部分定义域内都饱和，所以梯度学习非常困难（所以不鼓励作为前馈网络中的隐藏单元的激活函数，一般用于作为输出单元）。但是在一些特别的循环网络，很多概率模型，自编码器的一些额外要求**不能使用分段线性激活函数**，这时候sigmoid单元具有吸引力。
			- 双曲正切函数：$g(z)=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$ 标准形式，为了突出双曲正切函数性质也可以写成$tanh(z)=2α(2z)-1$
			- 在一定条件下，双曲正切激活函数会比logistic sigmoid更好。
			- 其他隐藏单元：
				- **径向基函数（RBF）**：$RBF(x)=exp(-\frac{(x-c)^2}{2σ^2})$ **c的值是中心点，σ是宽度，x是输入值。**
				- **softplus函数**：$g(a)=log(1+e^a)$ ,实际是对ReLu函数的一种平滑近似，可导，连续。
				- **硬双曲正切函数**：$g(a)=max(-1,min(1,a))$ 
				- 存在很多其他的激活函数，性能表现都良好，但是只有存在着比现有的激活函数要好才会进行发布。
		- PS：**无论是隐藏单元和隐藏单元的激活函数都是根据需求而选择，并不存在一种对任何情况都适合的激活函数。**
- **神经网络/模型**：
	- **前馈神经网络**：也叫多层感知机，由输入层->隐藏层->输出层。隐藏层可以是多层也可以是单层。
		- **无反馈连接**：数据只在神经网络向前传播，没有反馈连接形成循环结构。
		- **单向传播**：输入数据经过一系列的层和激活函数处理后，最终产生输出，没有跨层的连接反馈。
		- **层级结构**：网络通常由输入层、隐藏层（可以有多层）和输出层组成，层与层之间全连接连接也可以是部分连接。
		- **静态**：网络的输出只取决于当前的输入，不考虑过去的历史输入或网络的状态。**网络的每一次计算都是独立的，不会受到之前计算的影响。**
	- **卷积神经网络（CNN）**：[[卷积神经网络（CNN）]]
	- **RNN（循环神经网络）**：[[循环神经网络（RNN）]]
	- **生成对抗网络（GAN）**：
	-  **Capsule Networks**：
	- **GNN（图神经网络）**：
	- **自编码器**：[[深度学习（花书二）#^4e5970|自编码器]]
	- **模型**：
		- **预测稀疏分解(PSD)**:由**稀疏编码（是一个线性因子模型）**和**参数化自编码器**的混合模型，是无监督学习的模型。**适用于多种数据表示学习和信号处理任务。**
		- **Transformer**：
			- GPT：
			- BERT：
		- **ResNet**：
		- **RWKV**：
		- **UniRepLKNet**：
		- **StripedHyena**：
		- **PanGu-π**：
		- **StreamingLLM**：
		- **SeTformer**:
		- **Lightning Attention-2**:
		- **Mamba**：
	

	