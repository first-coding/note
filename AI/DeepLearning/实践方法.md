### 要想成功做出深度学习的项目，仅局限于存在什么算法和解决原理是不够的。

#在机器学习日常开发中需要决定以下几点： 
	[[#^b1f5db|决定是否收集更多数据]]
	[[实践方法#^f52938|是否增加/减少模型容量]]
	#是否添加/删除正则化项 
	#是否需要改进模型 

### 推荐实践设计流程：
	确定目标：
		使用什么样的误差度量，并为误差度量指定目标值。这些取决于实际的应用
		搭建一个端到端的工作流程，包括估计合适的性能度量
		搭建系统，并确定性能瓶颈。
			检查哪个部分的性能差于预期，以及是否是因为过拟合、欠拟合，或者数据或软件缺陷造成的。
		根据具体观察反复地进行增量式的改动。
			收集新数据、调整超参数或改进算法。
### [[基础知识#^1aa288|性能度量]]
### 默认的基准模型：
	
	根据问题复杂性选择模型，简单的线性权重就可以解决，使用逻辑回归这一类的就好了，对于图像识别这些用深度学习模型会更还
	根据数据的结构选择一类合适的模型
		固定大小的向量作为输入，使用全连接的前馈网络
		已知拓扑结构（例如图像），可以使用卷积神经网络
		输入或输出是一个序列，可以使用门控循环网络（LSTM/GRU）
	优化器的选择：SGD/Adam......
	正则化，提前终止，Dropout，批标准化等优化的选择。
	根据项目决定是否使用无监督学习。
### 决定是否收集更多数据 ^b1f5db
	判断训练集上的性能可否接受
		模型在训练集上的性能就很差，学习算法无法在训练集中学习出良好的模型，那么没必要收集更多数据
			应该尝试增加更多的网络层或每层增加更多的隐藏单元
			也可以通过调整学习率等超参数的措施改进学习算法
			如果更大的模型和优化算法效果不佳，问题可能和训练集的质量有关
		训练集上性能可以接收，开始度量测试集上的性能。
			如果存在测试集上的性能比训练集要差，那么收集更多的数据是最有效的解决方案之一
				但是要考虑收集更多数据的代价和可行性
			降低模型大小或改进正则化（调整超参数）

### 选择超参数 ^f52938
	手动选择：需要了解超参数做了什么，以及如何设置才能更好泛化
	自动选择：减少了手动选择的问题，但是伴随着更高的计算成本
		自动超参数优化算法：理想的学习算法应该是只需要输入一个数据集，就可以输出学习的函数。
			支持向量机和逻辑回归等这种算法，只需要一到两个超参数需要调整，它们也能表现出不错的性能。
			存在着一些超参数算法。
	网格搜索：对于每个超参数，选择一个有限值集去选择，通过笛卡尔乘积得到一组组的超参数，使用每组超参数去训练，挑选验证集误差最小的超参数作为最好的超参数。
	
	随机搜索：通过随机抽样来搜索参数空间的方法。相对于网格搜索，随机搜索的优点在于它不需要穷尽搜索整个参数空间，因此在参数空间较大时更具有可扩展性和效率。随机搜索可能无法保证找到全局最优解，但通常能在有限时间内找到足够好的解决方案。通过概率分布去选择超参数。
		均匀采样：在给定区间内每个可能数值被选择概率相同。
	贝叶斯优化：是一种基于贝叶斯理论的优化方法，它通过建立一个代理模型（通常是高斯过程或树形模型）来近似目标函数，然后利用后验分布来指导下一步参数选择的过程。贝叶斯优化在进行参数选择时能够利用先前的观察结果，因此通常比随机搜索和网格搜索更有效率。
![[db21bce44cac8f54768f46f7072e1c3.jpg]]
	
### 调试策略
	
	当一个机器学习系统效果不好时，很难判断是算法本身，还是实现的算法出错。
	另一个难点，大部分机器学习模型有多个自适应的部分。
	大部分神经网络的调试策略都是解决两个难题一个或两个：
		设计足够简单的情况，能够提前得到正确结果，判断模型预测是否与之相符
		设计一个测试，独立检查神经网络实现的各个部分。
	一些重要的调试检测：
		可视化计算中模型的行为：
			当训练模型检测图像中的对象时，查看一些模型检测到部分重叠的图像
			训练语音生成模型，试听一些生成的语音样本
		可视化最严重错误
		根据训练和测试误差检测软件
		拟合极小的数据集：
			当训练集有很大误差的时候，我们需要确定是否是真正欠拟合，还是其他问题。
				通常，即使是小模型也可以保证很好拟合一个足够小的数据集。可以用足够小的数据集进行测试。
		比较反向传播导数和数值导数
		监控激活函数值和梯度的直方图
	
	

		
	
