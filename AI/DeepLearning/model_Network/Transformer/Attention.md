- 在处理输入的多个元素时，不是均匀地关注所有输入，而是通过**加权**来让模型关注最重要的部分。
- 注意力机制中的嵌入向量由嵌入模型得到。
- 注意力机制中的Q，K，V都是来自输入向量的通过公式进行求
- **标准注意力机制**：
	- 数学公式：![[Pasted image 20250109173703.png]]
	- 流程：
		- ![[Pasted image 20250109174647.png]]![[Pasted image 20250109174740.png]]
- **自注意力机制**：特点是**Q,K,V都是来自同一个输入序列**。
	- 数学公式：![[Pasted image 20250109175028.png]]
	- 流程：
		- ![[Pasted image 20250109175057.png]]![[Pasted image 20250109175105.png]]
- **多头注意力机制**：核心思想：**并行计算多个不同的注意力头，每个头关注输入的不同部分，最后将多个头的输出拼接起来**。
	- 流程：![[Pasted image 20250109175220.png]]![[Pasted image 20250109175228.png]]
- ![[Pasted image 20250109175300.png]]